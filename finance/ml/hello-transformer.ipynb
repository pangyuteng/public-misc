{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/text/transformer\n",
    "# https://arxiv.org/pdf/1706.03762.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb 14 02:15:15 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.102.04   Driver Version: 450.102.04   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1070    On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| 23%   33C    P8     5W / 100W |     16MiB /  8119MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 1070    On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 23%   32C    P8     6W / 100W |      7MiB /  8119MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./ted_hrlr_translate_pt_en_converter.zip'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"ted_hrlr_translate_pt_en_converter\"\n",
    "tf.keras.utils.get_file(\n",
    "    f\"{model_name}.zip\",\n",
    "    f\"https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip\",\n",
    "    cache_dir='.', cache_subdir='', extract=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = tf.saved_model.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['detokenize',\n",
       " 'get_reserved_tokens',\n",
       " 'get_vocab_path',\n",
       " 'get_vocab_size',\n",
       " 'lookup',\n",
       " 'tokenize',\n",
       " 'tokenizer',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in dir(tokenizers.en) if not item.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n",
      "mas e se estes fatores fossem ativos ?\n",
      "mas eles não tinham a curiosidade de me testar .\n",
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n't test for curiosity .\n"
     ]
    }
   ],
   "source": [
    "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
    "    for pt in pt_examples.numpy():\n",
    "        print(pt.decode('utf-8'))\n",
    "\n",
    "    for en in en_examples.numpy():\n",
    "        print(en.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_pt = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
      "The original string: Transformer is awesome.\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7915 ----> T\n",
      "1248 ----> ran\n",
      "7946 ----> s\n",
      "7194 ----> former \n",
      "13 ----> is \n",
      "2799 ----> awesome\n",
      "7877 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a start and end token to the input and target.\n",
    "def encode(lang1, lang2):\n",
    "    lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "    lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "\n",
    "    return lang1, lang2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_encode(pt, en):\n",
    "    result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
    "    result_pt.set_shape([None])\n",
    "    result_en.set_shape([None])\n",
    "\n",
    "    return result_pt, result_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "\n",
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "    return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 38), dtype=int64, numpy=\n",
       " array([[8214,  342, 3032, ...,    0,    0,    0],\n",
       "        [8214,   95,  198, ...,    0,    0,    0],\n",
       "        [8214, 4479, 7990, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8214,  584,   12, ...,    0,    0,    0],\n",
       "        [8214,   59, 1548, ...,    0,    0,    0],\n",
       "        [8214,  118,   34, ...,    0,    0,    0]])>,\n",
       " <tf.Tensor: shape=(64, 40), dtype=int64, numpy=\n",
       " array([[8087,   98,   25, ...,    0,    0,    0],\n",
       "        [8087,   12,   20, ...,    0,    0,    0],\n",
       "        [8087,   12, 5453, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8087,   18, 2059, ...,    0,    0,    0],\n",
       "        [8087,   16, 1436, ...,    0,    0,    0],\n",
       "        [8087,   15,   57, ...,    0,    0,    0]])>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1, 1, 5)\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "a = create_padding_mask(x)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "print(temp.shape)\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead) \n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        #print(scaled_attention_logits.get_shape(),'scaled_attention_logits!!!')\n",
    "        #print(mask.get_shape(),'mask!!!')\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights\n",
    "\n",
    "def print_out(q, k, v):\n",
    "    temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "    print ('Attention weights are:')\n",
    "    print (temp_attn)\n",
    "    print ('Output is:')\n",
    "    print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n",
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)\n",
    "#Attention weights are:\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        #print(v.shape,k.shape,q.shape,mask.shape if mask is not None else None)\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        #print(scaled_attention.get_shape(),'scaled_attention###',mask.get_shape() if mask is not None else None)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights\n",
    "\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2\n",
    "\n",
    "    \n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "\n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "    \n",
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape\n",
    "\n",
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape\n",
    "\n",
    "\n",
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights\n",
    "\n",
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input, \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False,\n",
    "                              look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36, 8000])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights\n",
    "\n",
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_4 (Encoder)          multiple                  10656768  \n",
      "_________________________________________________________________\n",
      "decoder_4 (Decoder)          multiple                  12504064  \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            multiple                  4104000   \n",
      "=================================================================\n",
      "Total params: 27,264,832\n",
      "Trainable params: 27,264,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sample_transformer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)\n",
    "\n",
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "# ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "#                            optimizer=optimizer)\n",
    "\n",
    "# ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "#if ckpt_manager.latest_checkpoint:\n",
    "#    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "#    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "    print(enc_padding_mask.shape, combined_mask.shape, dec_padding_mask.shape)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                     True, \n",
    "                                     enc_padding_mask, \n",
    "                                     combined_mask, \n",
    "                                     dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(tar_real, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-------------------- 0\n",
      "(None, 1, 1, None) (None, 1, None, None) (None, 1, 1, None)\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, 1, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, 1, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, 1, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, 1, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, None, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, 1, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, None, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, 1, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, None, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, 1, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, None, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, 1, None) mask!!!\n",
      "(None, 1, 1, None) (None, 1, None, None) (None, 1, 1, None)\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, 1, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, 1, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, 1, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, 1, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, None, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, 1, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, None, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, 1, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, None, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, 1, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, None, None) mask!!!\n",
      "(None, 8, None, None) scaled_attention_logits!!!\n",
      "(None, 1, 1, None) mask!!!\n",
      "Epoch 1 Loss 7.1446 Accuracy 0.1157\n",
      "Time taken for 1 epoch: 81.19568157196045 secs\n",
      "\n",
      "epoch-------------------- 1\n",
      "Epoch 2 Loss 5.0436 Accuracy 0.2619\n",
      "Time taken for 1 epoch: 56.24385905265808 secs\n",
      "\n",
      "epoch-------------------- 2\n",
      "Epoch 3 Loss 4.4491 Accuracy 0.3218\n",
      "Time taken for 1 epoch: 56.25797724723816 secs\n",
      "\n",
      "epoch-------------------- 3\n",
      "Epoch 4 Loss 3.9552 Accuracy 0.3794\n",
      "Time taken for 1 epoch: 56.420620918273926 secs\n",
      "\n",
      "epoch-------------------- 4\n",
      "Epoch 5 Loss 3.4901 Accuracy 0.4359\n",
      "Time taken for 1 epoch: 56.378612995147705 secs\n",
      "\n",
      "epoch-------------------- 5\n",
      "Epoch 6 Loss 3.1026 Accuracy 0.4788\n",
      "Time taken for 1 epoch: 56.38197302818298 secs\n",
      "\n",
      "epoch-------------------- 6\n",
      "Epoch 7 Loss 2.7181 Accuracy 0.5222\n",
      "Time taken for 1 epoch: 56.38881802558899 secs\n",
      "\n",
      "epoch-------------------- 7\n",
      "Epoch 8 Loss 2.3958 Accuracy 0.5622\n",
      "Time taken for 1 epoch: 56.41383719444275 secs\n",
      "\n",
      "epoch-------------------- 8\n",
      "Epoch 9 Loss 2.1607 Accuracy 0.5922\n",
      "Time taken for 1 epoch: 56.420961141586304 secs\n",
      "\n",
      "epoch-------------------- 9\n",
      "Epoch 10 Loss 1.9841 Accuracy 0.6144\n",
      "Time taken for 1 epoch: 56.429688453674316 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print('epoch--------------------',epoch)\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    # inp -> portuguese, tar -> english\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "\n",
    "    if batch % 50 == 0:\n",
    "        print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        pass\n",
    "        #ckpt_save_path = ckpt_manager.save()\n",
    "        #print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "        #                                                     ckpt_save_path))\n",
    "\n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 11)\n",
      "(1, 1)\n",
      "tf.Tensor(\n",
      "[[   2 8088  433    1  145   14  211  198  145   44   14  198    5   80\n",
      "    44   14  198    5   80   19    2 8088    2 8088    2 8088    2 8088\n",
      "     2 8088    2 8088    2 8088    2 8088    2 8088    2 8088    2]], shape=(1, 41), dtype=int64)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument:  indices[0,1] = 8088 is not in [0, 7010)\n\t [[{{node StatefulPartitionedCall/Gather}}]]\n  (1) Invalid argument:  indices[0,1] = 8088 is not in [0, 7010)\n\t [[{{node StatefulPartitionedCall/Gather}}]]\n\t [[StatefulPartitionedCall/Gather/_8]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_restored_function_body_723039]\n\nFunction call stack:\nrestored_function_body -> restored_function_body\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-e8048fff50d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"this is a problem we have to solve .\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mtranslated_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslated_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mprint_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslated_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-e8048fff50d0>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence, max_length)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# shape: ()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  indices[0,1] = 8088 is not in [0, 7010)\n\t [[{{node StatefulPartitionedCall/Gather}}]]\n  (1) Invalid argument:  indices[0,1] = 8088 is not in [0, 7010)\n\t [[{{node StatefulPartitionedCall/Gather}}]]\n\t [[StatefulPartitionedCall/Gather/_8]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_restored_function_body_723039]\n\nFunction call stack:\nrestored_function_body -> restored_function_body\n"
     ]
    }
   ],
   "source": [
    "def evaluate(sentence, max_length=40):\n",
    "    # inp sentence is portuguese, hence adding the start and end token\n",
    "    sentence = tf.convert_to_tensor([sentence])\n",
    "    sentence = tokenizers.pt.tokenize(sentence).to_tensor()\n",
    "\n",
    "    encoder_input = sentence\n",
    "\n",
    "    # as the target is english, the first word to the transformer should be the\n",
    "    # english start token.\n",
    "    start, end = tokenizers.en.tokenize([''])[0]\n",
    "    output = tf.convert_to_tensor([start])\n",
    "    output = tf.expand_dims(output, 0)\n",
    "    print(encoder_input.shape)\n",
    "    print(output.shape)\n",
    "    for i in range(max_length):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "\n",
    "        # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "        # concatentate the predicted_id to the output which is given to the decoder\n",
    "        # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "        # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == end:\n",
    "            break\n",
    "    print(output)\n",
    "    # output.shape (1, tokens)\n",
    "    text = tokenizers.en.detokenize(output)[0] # shape: ()\n",
    "\n",
    "    tokens = tokenizers.en.lookup(output)[0]\n",
    "\n",
    "    return text, tokens, attention_weights\n",
    "\n",
    "sentence = \"este é um problema que temos que resolver.\"\n",
    "ground_truth = \"this is a problem we have to solve .\"\n",
    "\n",
    "translated_text, translated_tokens, attention_weights = evaluate(sentence)\n",
    "print_translation(sentence, translated_text, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "***************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
